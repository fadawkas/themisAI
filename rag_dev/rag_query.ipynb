{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca11a3a-1a3f-4ebb-ba1d-222d47296cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sentence-transformers faiss-cpu requests tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e03413a-1573-4808-b99c-9c37e9dbd634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, faiss, requests, numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb7cfd1-0923-4b10-af62-714e1239fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_DIR = \"/workspace/index_uu\"  # path index.faiss & metadata.jsonl\n",
    "VLLM_BASE = \"http://127.0.0.1:8002\"\n",
    "MODEL_NAME = \"google/gemma-3-4b-it\"\n",
    "LORA_NAME = \"hukum\"\n",
    "EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "TOP_K = 2\n",
    "MAX_TOKENS = 1024\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "Anda adalah asisten hukum profesional bergaya penulisan seperti artikel di Hukumonline.\n",
    "Jika informasi tidak ada di konteks, tuliskan:\n",
    "\"Tidak ditemukan dalam konteks yang tersedia.\"\n",
    "Tulislah jawaban dengan struktur analitis, lengkap, dan informatif, mencakup:\n",
    "1. Pendahuluan singkat konteks hukum.\n",
    "2. Penjelasan isi pasal/ayat yang relevan (kutip langsung jika ada).\n",
    "3. Penjabaran logika hukum dan interpretasinya.\n",
    "4. Poin-poin penting atau langkah hukum jika diperlukan.\n",
    "5. Bagian 'Dasar Hukum' di akhir, mencantumkan peraturan yang dikutip.\n",
    "6. Akhiri dengan kalimat sopan seperti 'Demikian penjelasan kami, semoga bermanfaat.'\n",
    "\n",
    "Gaya bahasa:\n",
    "- Gunakan bahasa hukum formal, sistematis, dan mudah dipahami masyarakat umum.\n",
    "- Hindari opini pribadi atau spekulasi.\n",
    "- Jika konteks tidak ditemukan, jawab: \"Berdasarkan konteks yang tersedia, informasi terkait belum ditemukan.\"\n",
    "\"\"\"\n",
    "\n",
    "USER_TEMPLATE = \"\"\"PERTANYAAN:\n",
    "{question}\n",
    "\n",
    "KONTEKS TERKAIT:\n",
    "{context}\n",
    "\n",
    "Sumber:\n",
    "{sources}\n",
    "\n",
    "Instruksi:\n",
    "- Susun jawaban menyerupai artikel hukum online yang lengkap dan berurutan.\n",
    "- Gunakan format berikut (bisa disesuaikan):\n",
    "\n",
    "PENJELASAN:\n",
    "(berikan uraian dan analisis hukum berdasarkan konteks)\n",
    "\n",
    "DASAR HUKUM:\n",
    "- Sebutkan UU, Pasal, dan peraturan yang relevan secara bernomor.\n",
    "\n",
    "CATATAN:\n",
    "Seluruh informasi hukum ini bersifat edukatif dan umum, bukan nasihat hukum spesifik.\n",
    "Untuk kasus konkret, konsultasikan kepada advokat atau konsultan hukum berizin.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e508358b-3cb5-4d5a-b97c-466a6ccfa4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_index(index_dir):\n",
    "    index = faiss.read_index(os.path.join(index_dir, \"index.faiss\"))\n",
    "    with open(os.path.join(index_dir, \"metadata.jsonl\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        meta = [json.loads(l) for l in f]\n",
    "    print(f\"Loaded {len(meta)} chunks | dim={index.d}\")\n",
    "    return index, meta\n",
    "\n",
    "index, meta = load_index(INDEX_DIR)\n",
    "encoder = SentenceTransformer(EMBED_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b5b12c-8f85-487f-9d78-d108d6bdb178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, index, meta, encoder, k=6):\n",
    "    qv = encoder.encode([query], normalize_embeddings=True).astype(\"float32\")\n",
    "    D, I = index.search(qv, k)\n",
    "    hits = []\n",
    "    for rank, (score, idx) in enumerate(zip(D[0], I[0]), 1):\n",
    "        r = meta[idx].copy()\n",
    "        r[\"rank\"] = rank\n",
    "        r[\"score\"] = float(score)\n",
    "        hits.append(r)\n",
    "    return hits\n",
    "\n",
    "def build_context_blocks(hits):\n",
    "    blocks, sources = [], []\n",
    "    for h in hits:\n",
    "        tag = h.get(\"number\") or h.get(\"case_number\") or h.get(\"title\",\"\")\n",
    "        blocks.append(f\"[C{h['rank']}] ({h.get('doc_type','')}) {h['text']}\")\n",
    "        sources.append(f\"[S{h['rank']}] {tag} ‚Äî {h.get('url','')}\")\n",
    "    return \"\\n\\n\".join(blocks), \"\\n\".join(sources)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23db569-bfad-47af-9c0a-7c44a23f71a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_vllm(question, context, sources):\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": USER_TEMPLATE.format(\n",
    "                question=question, context=context, sources=sources)}\n",
    "        ],\n",
    "        \"temperature\": 0.1,\n",
    "        \"top_p\": 0.9,\n",
    "        \"max_tokens\": MAX_TOKENS,\n",
    "    }\n",
    "    r = requests.post(f\"{VLLM_BASE}/v1/chat/completions\", json=payload, timeout=180)\n",
    "    r.raise_for_status()\n",
    "    return r.json()[\"choices\"][0][\"message\"][\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b61dcb6-3397-4a8c-a77c-4ccdbe331e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ganti pertanyaan sesuai kebutuhan\n",
    "question = \"Apa pendapat hukum indonesia mengenai perlindungan anak?\"\n",
    "\n",
    "# 1) Retrieve\n",
    "hits = search(question, index, meta, encoder, k=TOP_K)\n",
    "context, sources = build_context_blocks(hits)\n",
    "\n",
    "# 2) Generate\n",
    "answer = ask_vllm(question, context, sources)\n",
    "\n",
    "# 3) Show\n",
    "from IPython.display import Markdown\n",
    "display(Markdown(f\"### **Pertanyaan:** {question}\\n\\n---\\n\\n{answer}\\n\\n---\\n\\n**Sumber:**\\n{sources}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39482e0d-b529-45b4-9164-ad555421870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall\n",
    "import pandas as pd\n",
    "import json, os, time\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_similarity \n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings.base import embedding_factory\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5ac46f-3fc5-4600-8158-dff27d816e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lokasi index & vLLM mengikuti yang sudah kamu pakai\n",
    "INDEX_DIR = INDEX_DIR  # gunakan variabel dari cell sebelumnya\n",
    "VLLM_BASE = VLLM_BASE\n",
    "MODEL_NAME = MODEL_NAME\n",
    "EMBED_MODEL = EMBED_MODEL\n",
    "os.environ[\"DATA_PATH\"] = \"/workspace/QAs_Hukumonline_Test.json\"  # uploaded path\n",
    "\n",
    "# Output\n",
    "EVAL_OUTPUT_CSV = \"/workspace/ragas_results.csv\"\n",
    "\n",
    "# Retrieval & generasi\n",
    "TOP_K = 2\n",
    "MAX_TOKENS = MAX_TOKENS  # gunakan dari cell sebelumnya\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc9dc31-f753-44ba-b7b1-d81a256c1b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GEMINI_MODEL\"] = \"gemini-2.5-flash\"\n",
    "\n",
    "assert \"GOOGLE_API_KEY\" in os.environ, \"Set GOOGLE_API_KEY in env\"\n",
    "print(\"Config ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb440b5c-089f-492b-8c0d-af5189b44748",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.environ[\"DATA_PATH\"], \"r\", encoding=\"utf-8\") as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(raw).rename(columns={\"instruction\":\"question\",\"response\":\"ground_truth\"})\n",
    "print(f\"Rows: {len(df)}\")\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d19709-62ff-482a-8312-07994bf16260",
   "metadata": {},
   "outputs": [],
   "source": [
    "VLLM_URL = VLLM_BASE\n",
    "MODEL    = MODEL_NAME\n",
    "LORA     = LORA_NAME\n",
    "\n",
    "answers = []\n",
    "contexts_used = []\n",
    "\n",
    "start = time.time()\n",
    "for q in tqdm(df[\"question\"].tolist(), desc=\"Generating RAG answers (Gemma 3 4B + LoRA Hukum)\"):\n",
    "\n",
    "    # üîπ 1) Retrieve context from FAISS\n",
    "    hits = search(q, index, meta, encoder, k=TOP_K)     # ‚Üê from your RAG notebook\n",
    "    context, sources = build_context_blocks(hits)        # join text + sumber\n",
    "    contexts_used.append(context)\n",
    "\n",
    "    # üîπ 2) Build user prompt (includes question + context)\n",
    "    user_prompt = USER_TEMPLATE.format(question=q, context=context, sources=sources)\n",
    "\n",
    "    # üîπ 3) Send to vLLM\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.1,\n",
    "        \"max_tokens\": 1280,\n",
    "    }\n",
    "\n",
    "    r = requests.post(f\"{VLLM_URL}/v1/chat/completions\", json=payload, timeout=300)\n",
    "    r.raise_for_status()\n",
    "    answers.append(r.json()[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "\n",
    "df[\"context\"] = contexts_used\n",
    "df[\"answer\"] = answers\n",
    "out_csv = \"/workspace/gemma_rag_generations.csv\"\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(\"Saved\", out_csv)\n",
    "print(f\"Total time: {elapsed:.2f} seconds\")\n",
    "print(f\"Average per question: {elapsed / max(1,len(df)):.2f} seconds\")\n",
    "\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6785d74a-eb7f-429e-b2c9-18a197837c58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv-themisft)",
   "language": "python",
   "name": "venv-themisft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
