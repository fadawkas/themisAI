{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50f73bbe-39ad-4344-a854-7f9a782141b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   model  n_rows  avg_words  avg_type_token_ratio  \\\n",
      "0          Gemma-3-4B-it      96    485.333                 0.429   \n",
      "1    Qwen2.5-3B-Instruct      96    338.812                 0.545   \n",
      "2  Llama-3.2-3B-Instruct      96    242.875                 0.441   \n",
      "\n",
      "   answer_empties_%  exact_duplicate_answers_%  \n",
      "0               0.0                      0.000  \n",
      "1               0.0                      0.000  \n",
      "2               0.0                      1.042  \n",
      "\n",
      "Saved /workspace/model_text_metrics_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# --- Files ---\n",
    "paths = {\n",
    "    \"Gemma-3-4B-it\": \"/workspace/gemma_generations.csv\",\n",
    "    \"Qwen2.5-3B-Instruct\": \"/workspace/qwen_generations.csv\",\n",
    "    \"Llama-3.2-3B-Instruct\": \"/workspace/llama_generations.csv\",\n",
    "}\n",
    "\n",
    "# --- Text stats helper ---\n",
    "def text_stats(df):\n",
    "    answers = df[\"answer\"].fillna(\"\").astype(str)\n",
    "    # total words\n",
    "    word_counts = answers.apply(lambda t: len(re.findall(r\"\\w+(?:'\\w+)?\", t)))\n",
    "    avg_words = word_counts.mean()\n",
    "\n",
    "    # typeâ€“token ratio (unique words / total words per answer, then mean)\n",
    "    def ttr(text):\n",
    "        tokens = re.findall(r\"\\w+(?:'\\w+)?\", text.lower())\n",
    "        return len(set(tokens)) / len(tokens) if tokens else 0\n",
    "    ttrs = answers.apply(ttr)\n",
    "    avg_ttr = ttrs.mean()\n",
    "\n",
    "    # empty answers %\n",
    "    empties_pct = 100 * (answers.str.strip() == \"\").mean()\n",
    "\n",
    "    # duplicate exact answers %\n",
    "    duplicate_pct = 100 * (1 - answers.nunique() / len(answers)) if len(answers) else 0\n",
    "\n",
    "    return {\n",
    "        \"avg_words\": avg_words,\n",
    "        \"avg_type_token_ratio\": avg_ttr,\n",
    "        \"answer_empties_%\": empties_pct,\n",
    "        \"exact_duplicate_answers_%\": duplicate_pct,\n",
    "        \"n_rows\": len(answers)\n",
    "    }\n",
    "\n",
    "# --- Run for each model ---\n",
    "rows = []\n",
    "for name, path in paths.items():\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        if \"answer\" not in df.columns:\n",
    "            raise ValueError(f\"'answer' column not found in {path}\")\n",
    "        metrics = text_stats(df)\n",
    "        metrics[\"model\"] = name\n",
    "        rows.append(metrics)\n",
    "    except Exception as e:\n",
    "        print(f\"[skip] {name}: {e}\")\n",
    "\n",
    "summary = pd.DataFrame(rows)\n",
    "summary = summary[\n",
    "    [\"model\", \"n_rows\", \"avg_words\", \"avg_type_token_ratio\", \"answer_empties_%\", \"exact_duplicate_answers_%\"]\n",
    "]\n",
    "\n",
    "print(summary.round(3))\n",
    "\n",
    "# Optionally save\n",
    "summary.to_csv(\"/workspace/model_text_metrics_summary.csv\", index=False)\n",
    "print(\"\\nSaved /workspace/model_text_metrics_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be38c050-c947-4350-8a7e-52c0ce0dc75b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llmEnv)",
   "language": "python",
   "name": "llmenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
