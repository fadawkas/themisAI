{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "146f77d5-1ea9-4af0-9b95-fed2703bdd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, requests, time\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_similarity   # <-- new name\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings.base import embedding_factory\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec560f5f-c666-494d-8244-07abfe3b7e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAbc8VTKoFfXGuMZbc0OvQ_L7U-K8LHg1A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "120566ab-5e5c-4886-ba23-82e6c792fc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config ready\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"DATA_PATH\"] = \"/workspace/QAs_Hukumonline_Test.json\"  # uploaded path\n",
    "os.environ[\"VLLM_BASE\"] = \"http://127.0.0.1:8002\"\n",
    "os.environ[\"VLLM_MODEL\"] = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "os.environ[\"GEMINI_MODEL\"] = \"gemini-2.5-flash\"\n",
    "\n",
    "assert \"GOOGLE_API_KEY\" in os.environ, \"Set GOOGLE_API_KEY in env first!\"\n",
    "print(\"Config ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a49a48c7-dbc1-430d-8fae-8bb54feb2629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 96\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apa bunyi Pasal 187 KUHP? Benarkah Pasal 187 K...</td>\n",
       "      <td>Pasal 187KUHPlama yang saat artikel ini diterb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Orang gila apakah termasuk subjek hukum? Apaka...</td>\n",
       "      <td>Ilmu hukum pidana mengenal adanya alasan pengh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Suami saya tersangkut kasus pencurian dengan p...</td>\n",
       "      <td>Tahanan adalah tersangka atau terdakwa yang di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Apa bunyi Pasal 187 KUHP? Benarkah Pasal 187 K...   \n",
       "1  Orang gila apakah termasuk subjek hukum? Apaka...   \n",
       "2  Suami saya tersangkut kasus pencurian dengan p...   \n",
       "\n",
       "                                        ground_truth  \n",
       "0  Pasal 187KUHPlama yang saat artikel ini diterb...  \n",
       "1  Ilmu hukum pidana mengenal adanya alasan pengh...  \n",
       "2  Tahanan adalah tersangka atau terdakwa yang di...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.environ[\"DATA_PATH\"], \"r\", encoding=\"utf-8\") as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(raw).rename(columns={\"instruction\":\"question\",\"response\":\"ground_truth\"})\n",
    "print(f\"Rows: {len(df)}\")\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b41c2c49-17c4-4597-b4b7-607959541f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers (Qwen 2.5 3B): 100%|██████████| 96/96 [15:35<00:00,  9.75s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /workspace/qwen_generations.csv\n",
      "Total time: 935.72 seconds\n",
      "Average per question: 9.75 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apa bunyi Pasal 187 KUHP? Benarkah Pasal 187 K...</td>\n",
       "      <td>Pasal 187KUHPlama yang saat artikel ini diterb...</td>\n",
       "      <td>Maaf, saya tidak memiliki akses langsung ke ko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Orang gila apakah termasuk subjek hukum? Apaka...</td>\n",
       "      <td>Ilmu hukum pidana mengenal adanya alasan pengh...</td>\n",
       "      <td>Pasal 44 dalam Kitab Undang-Undang Hukum Pidan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Suami saya tersangkut kasus pencurian dengan p...</td>\n",
       "      <td>Tahanan adalah tersangka atau terdakwa yang di...</td>\n",
       "      <td>Situasi yang Anda alami tentu sangat menyakitk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Apa bunyi Pasal 187 KUHP? Benarkah Pasal 187 K...   \n",
       "1  Orang gila apakah termasuk subjek hukum? Apaka...   \n",
       "2  Suami saya tersangkut kasus pencurian dengan p...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  Pasal 187KUHPlama yang saat artikel ini diterb...   \n",
       "1  Ilmu hukum pidana mengenal adanya alasan pengh...   \n",
       "2  Tahanan adalah tersangka atau terdakwa yang di...   \n",
       "\n",
       "                                              answer  \n",
       "0  Maaf, saya tidak memiliki akses langsung ke ko...  \n",
       "1  Pasal 44 dalam Kitab Undang-Undang Hukum Pidan...  \n",
       "2  Situasi yang Anda alami tentu sangat menyakitk...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VLLM_URL = os.environ[\"VLLM_BASE\"]\n",
    "MODEL = os.environ[\"VLLM_MODEL\"]\n",
    "\n",
    "answers = []\n",
    "\n",
    "start = time.time()\n",
    "for q in tqdm(df[\"question\"].tolist(), desc=\"Generating answers (Qwen 2.5 3B)\"):\n",
    "    payload = {\"model\": MODEL, \"messages\": [{\"role\":\"user\",\"content\": q}], \"temperature\": 0.2}\n",
    "    r = requests.post(f\"{VLLM_URL}/v1/chat/completions\", json=payload, timeout=300)\n",
    "    r.raise_for_status()\n",
    "    answers.append(r.json()[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "\n",
    "df[\"answer\"] = answers\n",
    "df.to_csv(\"/workspace/qwen_generations.csv\", index=False)\n",
    "print(\"Saved /workspace/qwen_generations.csv\")\n",
    "\n",
    "print(f\"Total time: {elapsed:.2f} seconds\")\n",
    "print(f\"Average per question: {elapsed / len(df):.2f} seconds\")\n",
    "\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cb09e35-39f7-4e9b-aedb-3e02eaf2bd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4345/4276113321.py:9: DeprecationWarning: LangchainLLMWrapper is deprecated and will be removed in a future version. Use the modern LLM providers instead: from ragas.llms.base import llm_factory; llm = llm_factory('gpt-4o-mini') or from ragas.llms.base import instructor_llm_factory; llm = instructor_llm_factory('openai', client=openai_client)\n",
      "  llm = LangchainLLMWrapper(judge_llm)\n",
      "Evaluating: 100%|██████████| 96/96 [00:03<00:00, 29.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-row dataframe shape: (96, 1)\n",
      "   answer_similarity_score\n",
      "0                 0.639990\n",
      "1                 0.734987\n",
      "2                 0.775046\n",
      "Saved:\n",
      "  - /workspace/qwen_ragas_overall.csv\n",
      "  - /workspace/qwen_ragas_per_row.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_similarity_score_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.736049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   answer_similarity_score_mean\n",
       "0                      0.736049"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = \"/workspace/qwen_generations.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "assert {\"question\",\"answer\",\"ground_truth\"}.issubset(df.columns), f\"Missing columns: {df.columns.tolist()}\"\n",
    "\n",
    "judge_llm = ChatGoogleGenerativeAI(\n",
    "    model=os.environ.get(\"GEMINI_MODEL\", \"gemini-2.5-flash\"),\n",
    "    google_api_key=os.environ[\"GOOGLE_API_KEY\"],\n",
    ")\n",
    "llm = LangchainLLMWrapper(judge_llm)\n",
    "emb = embedding_factory(provider=\"huggingface\",\n",
    "                        model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "ragas_ds = Dataset.from_pandas(df[[\"question\",\"answer\",\"ground_truth\"]])\n",
    "\n",
    "\n",
    "executor = evaluate(\n",
    "    ragas_ds,\n",
    "    metrics=[answer_similarity],\n",
    "    llm=llm,\n",
    "    embeddings=emb,\n",
    "    show_progress=True,\n",
    "    return_executor=True,\n",
    ")\n",
    "\n",
    "raw = None\n",
    "if hasattr(executor, \"results\"):\n",
    "    try:\n",
    "        raw = executor.results()\n",
    "    except Exception:\n",
    "        raw = executor.results\n",
    "else:\n",
    "    raw = executor\n",
    "\n",
    "if not isinstance(raw, list):\n",
    "    raise RuntimeError(f\"Expected a list of floats but got {type(raw)}\")\n",
    "\n",
    "per_row_df = pd.DataFrame(raw, columns=[\"answer_similarity_score\"])\n",
    "print(\"Per-row dataframe shape:\", per_row_df.shape)\n",
    "print(per_row_df.head(3))\n",
    "\n",
    "overall_df = per_row_df.mean().to_frame().T\n",
    "overall_df.columns = [c + \"_mean\" for c in overall_df.columns]\n",
    "\n",
    "overall_df.to_csv(\"/workspace/qwen_ragas_overall.csv\", index=False)\n",
    "per_row_df.to_csv(\"/workspace/qwen_ragas_per_row.csv\", index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"  - /workspace/qwen_ragas_overall.csv\")\n",
    "print(\"  - /workspace/qwen_ragas_per_row.csv\")\n",
    "\n",
    "overall_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f39fbd-2c49-47f9-838e-b1f5e5d168eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llmEnv)",
   "language": "python",
   "name": "llmenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
