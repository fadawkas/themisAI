{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "146f77d5-1ea9-4af0-9b95-fed2703bdd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, requests, time\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_similarity \n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings.base import embedding_factory\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec560f5f-c666-494d-8244-07abfe3b7e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAbc8VTKoFfXGuMZbc0OvQ_L7U-K8LHg1A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "120566ab-5e5c-4886-ba23-82e6c792fc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config ready\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"DATA_PATH\"] = \"/workspace/QAs_Hukumonline_Test.json\"  # uploaded path\n",
    "os.environ[\"VLLM_BASE\"] = \"http://127.0.0.1:8000\"\n",
    "os.environ[\"VLLM_MODEL\"] = \"google/gemma-3-4b-it\"\n",
    "os.environ[\"GEMINI_MODEL\"] = \"gemini-2.5-flash\"\n",
    "\n",
    "assert \"GOOGLE_API_KEY\" in os.environ, \"Set GOOGLE_API_KEY in env first!\"\n",
    "print(\"Config ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a49a48c7-dbc1-430d-8fae-8bb54feb2629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 96\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apa bunyi Pasal 187 KUHP? Benarkah Pasal 187 K...</td>\n",
       "      <td>Pasal 187KUHPlama yang saat artikel ini diterb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Orang gila apakah termasuk subjek hukum? Apaka...</td>\n",
       "      <td>Ilmu hukum pidana mengenal adanya alasan pengh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Suami saya tersangkut kasus pencurian dengan p...</td>\n",
       "      <td>Tahanan adalah tersangka atau terdakwa yang di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Apa bunyi Pasal 187 KUHP? Benarkah Pasal 187 K...   \n",
       "1  Orang gila apakah termasuk subjek hukum? Apaka...   \n",
       "2  Suami saya tersangkut kasus pencurian dengan p...   \n",
       "\n",
       "                                        ground_truth  \n",
       "0  Pasal 187KUHPlama yang saat artikel ini diterb...  \n",
       "1  Ilmu hukum pidana mengenal adanya alasan pengh...  \n",
       "2  Tahanan adalah tersangka atau terdakwa yang di...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.environ[\"DATA_PATH\"], \"r\", encoding=\"utf-8\") as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(raw).rename(columns={\"instruction\":\"question\",\"response\":\"ground_truth\"})\n",
    "print(f\"Rows: {len(df)}\")\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41c2c49-17c4-4597-b4b7-607959541f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers (Gemma 3 4B): 100%|██████████| 96/96 [25:35<00:00, 15.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /workspace/gemma_generations.csv\n",
      "Total time: 1535.44 seconds\n",
      "Average per question: 15.99 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apa bunyi Pasal 187 KUHP? Benarkah Pasal 187 K...</td>\n",
       "      <td>Pasal 187KUHPlama yang saat artikel ini diterb...</td>\n",
       "      <td>Pasal 187 Kitab Undang-Undang Hukum Pidana (KU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Orang gila apakah termasuk subjek hukum? Apaka...</td>\n",
       "      <td>Ilmu hukum pidana mengenal adanya alasan pengh...</td>\n",
       "      <td>Pertanyaan yang sangat menarik dan kompleks me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Suami saya tersangkut kasus pencurian dengan p...</td>\n",
       "      <td>Tahanan adalah tersangka atau terdakwa yang di...</td>\n",
       "      <td>Situasi yang Anda alami sangat berat dan membu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Apa bunyi Pasal 187 KUHP? Benarkah Pasal 187 K...   \n",
       "1  Orang gila apakah termasuk subjek hukum? Apaka...   \n",
       "2  Suami saya tersangkut kasus pencurian dengan p...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  Pasal 187KUHPlama yang saat artikel ini diterb...   \n",
       "1  Ilmu hukum pidana mengenal adanya alasan pengh...   \n",
       "2  Tahanan adalah tersangka atau terdakwa yang di...   \n",
       "\n",
       "                                              answer  \n",
       "0  Pasal 187 Kitab Undang-Undang Hukum Pidana (KU...  \n",
       "1  Pertanyaan yang sangat menarik dan kompleks me...  \n",
       "2  Situasi yang Anda alami sangat berat dan membu...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cb09e35-39f7-4e9b-aedb-3e02eaf2bd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5841/3393652965.py:9: DeprecationWarning: LangchainLLMWrapper is deprecated and will be removed in a future version. Use the modern LLM providers instead: from ragas.llms.base import llm_factory; llm = llm_factory('gpt-4o-mini') or from ragas.llms.base import instructor_llm_factory; llm = instructor_llm_factory('openai', client=openai_client)\n",
      "  llm = LangchainLLMWrapper(judge_llm)\n",
      "Evaluating: 100%|██████████| 96/96 [00:03<00:00, 27.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-row dataframe shape: (96, 1)\n",
      "   answer_similarity_score\n",
      "0                 0.773469\n",
      "1                 0.651248\n",
      "2                 0.710802\n",
      "Saved:\n",
      "  - /workspace/gemma_ragas_overall.csv\n",
      "  - /workspace/gemma_ragas_per_row.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_similarity_score_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.740955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   answer_similarity_score_mean\n",
       "0                      0.740955"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = \"/workspace/gemma_generations.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "assert {\"question\",\"answer\",\"ground_truth\"}.issubset(df.columns), f\"Missing columns: {df.columns.tolist()}\"\n",
    "\n",
    "judge_llm = ChatGoogleGenerativeAI(\n",
    "    model=os.environ.get(\"GEMINI_MODEL\", \"gemini-2.5-flash\"),\n",
    "    google_api_key=os.environ[\"GOOGLE_API_KEY\"],\n",
    ")\n",
    "llm = LangchainLLMWrapper(judge_llm)\n",
    "emb = embedding_factory(provider=\"huggingface\",\n",
    "                        model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "ragas_ds = Dataset.from_pandas(df[[\"question\",\"answer\",\"ground_truth\"]])\n",
    "\n",
    "\n",
    "executor = evaluate(\n",
    "    ragas_ds,\n",
    "    metrics=[answer_similarity],\n",
    "    llm=llm,\n",
    "    embeddings=emb,\n",
    "    show_progress=True,\n",
    "    return_executor=True,\n",
    ")\n",
    "\n",
    "raw = None\n",
    "if hasattr(executor, \"results\"):\n",
    "    try:\n",
    "        raw = executor.results()\n",
    "    except Exception:\n",
    "        raw = executor.results\n",
    "else:\n",
    "    raw = executor\n",
    "\n",
    "if not isinstance(raw, list):\n",
    "    raise RuntimeError(f\"Expected a list of floats but got {type(raw)}\")\n",
    "\n",
    "per_row_df = pd.DataFrame(raw, columns=[\"answer_similarity_score\"])\n",
    "print(\"Per-row dataframe shape:\", per_row_df.shape)\n",
    "print(per_row_df.head(3))\n",
    "\n",
    "overall_df = per_row_df.mean().to_frame().T\n",
    "overall_df.columns = [c + \"_mean\" for c in overall_df.columns]\n",
    "\n",
    "overall_df.to_csv(\"/workspace/gemma_ragas_overall.csv\", index=False)\n",
    "per_row_df.to_csv(\"/workspace/gemma_ragas_per_row.csv\", index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"  - /workspace/gemma_ragas_overall.csv\")\n",
    "print(\"  - /workspace/gemma_ragas_per_row.csv\")\n",
    "\n",
    "overall_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdf0ff1-8b30-43f1-90e6-cfa70b447e94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llmEnv)",
   "language": "python",
   "name": "llmenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
