{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dce8831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import os, json, requests, time\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_similarity\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings.base import embedding_factory\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc082b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ✅ SET KEY DI ENV, JANGAN HARDCODE\n",
    "# di terminal / notebook before run:\n",
    "# export GOOGLE_API_KEY=\".....\"\n",
    "assert os.environ.get(\"GOOGLE_API_KEY\"), \"Set GOOGLE_API_KEY in env (jangan hardcode di notebook).\"\n",
    "print(\"GOOGLE_API_KEY exists ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809c432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ---- Config untuk Qwen ----\n",
    "os.environ[\"DATA_PATH\"]   = \"/workspace/QAs_Hukumonline_Test.json\"\n",
    "os.environ[\"VLLM_BASE\"]   = \"http://127.0.0.1:8002\"\n",
    "\n",
    "# model base vLLM (Qwen)\n",
    "os.environ[\"VLLM_MODEL\"]  = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "\n",
    "# nama LoRA module yang kamu register di vLLM (contoh: \"hukum_qwen\")\n",
    "# pastikan sama persis dengan yang ada di server vLLM kamu\n",
    "os.environ[\"LORA_NAME\"]   = \"hukum_qwen\"\n",
    "\n",
    "# Gemini judge model\n",
    "os.environ[\"GEMINI_MODEL\"] = \"gemini-2.5-flash\"\n",
    "\n",
    "print(\"Config ready\")\n",
    "print(\"VLLM:\", os.environ[\"VLLM_BASE\"], os.environ[\"VLLM_MODEL\"], \"LoRA:\", os.environ[\"LORA_NAME\"])\n",
    "print(\"GEMINI:\", os.environ[\"GEMINI_MODEL\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245a02e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Load test data\n",
    "with open(os.environ[\"DATA_PATH\"], \"r\", encoding=\"utf-8\") as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(raw).rename(columns={\"instruction\":\"question\",\"response\":\"ground_truth\"})\n",
    "print(f\"Rows: {len(df)}\")\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b019ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Generate answers using vLLM (Qwen 2.5 3B + LoRA)\n",
    "VLLM_URL = os.environ[\"VLLM_BASE\"]\n",
    "MODEL    = os.environ[\"VLLM_MODEL\"]\n",
    "LORA     = os.environ[\"LORA_NAME\"]\n",
    "\n",
    "answers = []\n",
    "start = time.time()\n",
    "\n",
    "for q in tqdm(df[\"question\"].tolist(), desc=\"Generating answers (Qwen2.5-3B + LoRA)\"):\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [\n",
    "            # Optional system prompt biar konsisten\n",
    "            {\"role\":\"system\",\"content\":\"Anda adalah asisten hukum yang akurat, padat, dan mengutip dasar hukum bila relevan.\"},\n",
    "            {\"role\":\"user\",\"content\": q}\n",
    "        ],\n",
    "        \"temperature\": 0.2,\n",
    "        \"max_tokens\": 1280,\n",
    "        # vLLM: apply LoRA\n",
    "        \"extra_body\": {\"lora_modules\": [LORA]},\n",
    "    }\n",
    "\n",
    "    r = requests.post(f\"{VLLM_URL}/v1/chat/completions\", json=payload, timeout=300)\n",
    "    r.raise_for_status()\n",
    "    answers.append(r.json()[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "\n",
    "df[\"answer\"] = answers\n",
    "\n",
    "out_csv = \"/workspace/qwen_generations_lora.csv\"\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(\"Saved\", out_csv)\n",
    "\n",
    "print(f\"Total time: {elapsed:.2f} seconds\")\n",
    "print(f\"Average per question: {elapsed / max(1,len(df)):.2f} seconds\")\n",
    "\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c95c4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# RAGAS answer_similarity evaluation (Gemini as judge + HF embedding)\n",
    "csv_path = \"/workspace/qwen_generations_lora.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "assert {\"question\",\"answer\",\"ground_truth\"}.issubset(df.columns), f\"Missing columns: {df.columns.tolist()}\"\n",
    "\n",
    "judge_llm = ChatGoogleGenerativeAI(\n",
    "    model=os.environ[\"GEMINI_MODEL\"],\n",
    "    google_api_key=os.environ[\"GOOGLE_API_KEY\"],\n",
    ")\n",
    "llm = LangchainLLMWrapper(judge_llm)\n",
    "\n",
    "emb = embedding_factory(\n",
    "    provider=\"huggingface\",\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "ragas_ds = Dataset.from_pandas(df[[\"question\",\"answer\",\"ground_truth\"]])\n",
    "\n",
    "executor = evaluate(\n",
    "    ragas_ds,\n",
    "    metrics=[answer_similarity],\n",
    "    llm=llm,\n",
    "    embeddings=emb,\n",
    "    show_progress=True,\n",
    "    return_executor=True,\n",
    ")\n",
    "\n",
    "raw = None\n",
    "if hasattr(executor, \"results\"):\n",
    "    try:\n",
    "        raw = executor.results()\n",
    "    except Exception:\n",
    "        raw = executor.results\n",
    "else:\n",
    "    raw = executor\n",
    "\n",
    "if not isinstance(raw, list):\n",
    "    raise RuntimeError(f\"Expected a list of floats but got {type(raw)}\")\n",
    "\n",
    "per_row_df = pd.DataFrame(raw, columns=[\"answer_similarity_score\"])\n",
    "print(\"Per-row dataframe shape:\", per_row_df.shape)\n",
    "print(per_row_df.head(3))\n",
    "\n",
    "overall_df = per_row_df.mean().to_frame().T\n",
    "overall_df.columns = [c + \"_mean\" for c in overall_df.columns]\n",
    "\n",
    "overall_df.to_csv(\"/workspace/qwen_ragas_overall_lora.csv\", index=False)\n",
    "per_row_df.to_csv(\"/workspace/qwen_ragas_per_row_lora.csv\", index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"  - /workspace/qwen_ragas_overall_lora.csv\")\n",
    "print(\"  - /workspace/qwen_ragas_per_row_lora.csv\")\n",
    "\n",
    "overall_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6069ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Text stats summary (avg words, TTR, empties, duplicates) for Qwen LoRA\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "paths = {\n",
    "    \"Qwen2.5-3B-Instruct-LoRA\": \"/workspace/qwen_generations_lora.csv\",\n",
    "}\n",
    "\n",
    "def text_stats(df):\n",
    "    answers = df[\"answer\"].fillna(\"\").astype(str)\n",
    "\n",
    "    word_counts = answers.apply(lambda t: len(re.findall(r\"\\w+(?:'\\w+)?\", t)))\n",
    "    avg_words = word_counts.mean()\n",
    "\n",
    "    def ttr(text):\n",
    "        tokens = re.findall(r\"\\w+(?:'\\w+)?\", text.lower())\n",
    "        return len(set(tokens)) / len(tokens) if tokens else 0\n",
    "\n",
    "    ttrs = answers.apply(ttr)\n",
    "    avg_ttr = ttrs.mean()\n",
    "\n",
    "    empties_pct = 100 * (answers.str.strip() == \"\").mean()\n",
    "    duplicate_pct = 100 * (1 - answers.nunique() / len(answers)) if len(answers) else 0\n",
    "\n",
    "    return {\n",
    "        \"avg_words\": avg_words,\n",
    "        \"avg_type_token_ratio\": avg_ttr,\n",
    "        \"answer_empties_%\": empties_pct,\n",
    "        \"exact_duplicate_answers_%\": duplicate_pct,\n",
    "        \"n_rows\": len(answers)\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "for name, path in paths.items():\n",
    "    try:\n",
    "        dfm = pd.read_csv(path)\n",
    "        if \"answer\" not in dfm.columns:\n",
    "            raise ValueError(f\"'answer' column not found in {path}\")\n",
    "        metrics = text_stats(dfm)\n",
    "        metrics[\"model\"] = name\n",
    "        rows.append(metrics)\n",
    "    except Exception as e:\n",
    "        print(f\"[skip] {name}: {e}\")\n",
    "\n",
    "summary = pd.DataFrame(rows)[\n",
    "    [\"model\", \"n_rows\", \"avg_words\", \"avg_type_token_ratio\", \"answer_empties_%\", \"exact_duplicate_answers_%\"]\n",
    "]\n",
    "\n",
    "print(summary.round(3))\n",
    "\n",
    "summary.to_csv(\"/workspace/model_text_metrics_summary_qwen_lora.csv\", index=False)\n",
    "print(\"\\nSaved /workspace/model_text_metrics_summary_qwen_lora.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
